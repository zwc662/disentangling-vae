{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Deterministic Policy Gradients (DDPG)\n",
    "---\n",
    "In this notebook, we train DDPG with OpenAI Gym's Pendulum-v0 environment.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import dynamics\n",
    "importlib.reload(dynamics)\n",
    "import ddpg_agent\n",
    "importlib.reload(ddpg_agent)\n",
    "\n",
    "\n",
    "from dynamics import Dynamics\n",
    "from ddpg_agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate the Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Dynamics(dataset = 'mnist', vae = 'VAE_mnist', cls = 'CLS_mnist', target = None)\n",
    "env.reset()\n",
    "state_size = env.state_size()\n",
    "action_size = env.action_size()\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agent with DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: -27047.94\n",
      "Episode 200\tAverage Score: -27049.40\n",
      "Episode 300\tAverage Score: -27050.05\n",
      "Episode 400\tAverage Score: -27050.06\n",
      "Episode 500\tAverage Score: -27050.21\n",
      "Episode 600\tAverage Score: -27050.18\n",
      "Episode 700\tAverage Score: -27050.14\n",
      "Episode 800\tAverage Score: -27050.13\n",
      "Episode 900\tAverage Score: -27044.38\n",
      "Episode 1000\tAverage Score: -27046.30\n",
      "Episode 1100\tAverage Score: -27046.49\n",
      "Episode 1200\tAverage Score: -27047.11\n",
      "Episode 1300\tAverage Score: -27050.31\n",
      "Episode 1400\tAverage Score: -27050.51\n",
      "Episode 1500\tAverage Score: -27043.09\n",
      "Episode 1600\tAverage Score: -27040.64\n",
      "Episode 1700\tAverage Score: -27040.64\n",
      "Episode 1800\tAverage Score: -27040.64\n",
      "Episode 1900\tAverage Score: -27040.64\n",
      "Episode 2000\tAverage Score: -27040.64\n",
      "Episode 2100\tAverage Score: -27040.64\n",
      "Episode 2200\tAverage Score: -26666.63\n",
      "Episode 2300\tAverage Score: -26638.66\n",
      "Episode 2400\tAverage Score: -26768.51\n",
      "Episode 2500\tAverage Score: -26766.08\n",
      "Episode 2600\tAverage Score: -26748.53\n",
      "Episode 2700\tAverage Score: -26677.00\n",
      "Episode 2800\tAverage Score: -26665.90\n",
      "Episode 2900\tAverage Score: -26762.73\n",
      "Episode 3000\tAverage Score: -26745.69\n",
      "Episode 3100\tAverage Score: -26724.75\n",
      "Episode 3200\tAverage Score: -26722.82\n",
      "Episode 3300\tAverage Score: -26730.39\n",
      "Episode 3400\tAverage Score: -26611.68\n",
      "Episode 3500\tAverage Score: -26640.33\n",
      "Episode 3600\tAverage Score: -26649.61\n",
      "Episode 3700\tAverage Score: -26715.76\n",
      "Episode 3800\tAverage Score: -26791.47\n",
      "Episode 3900\tAverage Score: -26593.31\n",
      "Episode 4000\tAverage Score: -26575.75\n",
      "Episode 4100\tAverage Score: -26579.89\n",
      "Episode 4200\tAverage Score: -26505.92\n",
      "Episode 4300\tAverage Score: -26536.19\n",
      "Episode 4400\tAverage Score: -26561.20\n",
      "Episode 4500\tAverage Score: -26535.67\n",
      "Episode 4600\tAverage Score: -26500.60\n",
      "Episode 4700\tAverage Score: -26526.65\n",
      "Episode 4800\tAverage Score: -26741.14\n",
      "Episode 4900\tAverage Score: -26747.94\n",
      "Episode 5000\tAverage Score: -26740.15\n",
      "Episode 5100\tAverage Score: -26745.71\n",
      "Episode 5200\tAverage Score: -26767.13\n",
      "Episode 5300\tAverage Score: -26769.32\n",
      "Episode 5400\tAverage Score: -26791.21\n",
      "Episode 5500\tAverage Score: -26847.31\n",
      "Episode 5600\tAverage Score: -26828.35\n",
      "Episode 5700\tAverage Score: -26783.51\n",
      "Episode 5800\tAverage Score: -26772.35\n",
      "Episode 5900\tAverage Score: -26781.11\n",
      "Episode 6000\tAverage Score: -26776.90\n",
      "Episode 6100\tAverage Score: -26773.03\n",
      "Episode 6200\tAverage Score: -26769.61\n",
      "Episode 6300\tAverage Score: -26769.37\n",
      "Episode 6400\tAverage Score: -26770.26\n",
      "Episode 6500\tAverage Score: -26768.82\n",
      "Episode 6600\tAverage Score: -26767.37\n",
      "Episode 6700\tAverage Score: -26767.57\n",
      "Episode 6800\tAverage Score: -26767.52\n",
      "Episode 6900\tAverage Score: -26767.58\n",
      "Episode 7000\tAverage Score: -26767.75\n",
      "Episode 7100\tAverage Score: -26769.61\n",
      "Episode 7200\tAverage Score: -26769.81\n",
      "Episode 7300\tAverage Score: -26750.72\n",
      "Episode 7400\tAverage Score: -26700.38\n",
      "Episode 7500\tAverage Score: -26771.08\n",
      "Episode 7600\tAverage Score: -26784.44\n",
      "Episode 7700\tAverage Score: -26818.92\n",
      "Episode 7800\tAverage Score: -26680.02\n",
      "Episode 7900\tAverage Score: -26736.70\n",
      "Episode 8000\tAverage Score: -26788.14\n",
      "Episode 8100\tAverage Score: -26777.67\n",
      "Episode 8200\tAverage Score: -26771.11\n",
      "Episode 8300\tAverage Score: -26713.67\n",
      "Episode 8400\tAverage Score: -26649.87\n",
      "Episode 8500\tAverage Score: -26654.79\n",
      "Episode 8600\tAverage Score: -26649.80\n",
      "Episode 8700\tAverage Score: -26649.92\n",
      "Episode 8800\tAverage Score: -26649.88\n",
      "Episode 8900\tAverage Score: -26649.75\n",
      "Episode 9000\tAverage Score: -26649.75\n",
      "Episode 9100\tAverage Score: -26650.03\n",
      "Episode 9200\tAverage Score: -26649.84\n",
      "Episode 9300\tAverage Score: -26649.75\n",
      "Episode 9400\tAverage Score: -26649.92\n",
      "Episode 9500\tAverage Score: -26649.84\n",
      "Episode 9600\tAverage Score: -26649.77\n",
      "Episode 9700\tAverage Score: -26649.86\n",
      "Episode 9800\tAverage Score: -26649.81\n",
      "Episode 9900\tAverage Score: -26650.03\n",
      "Episode 9974\tAverage Score: -26649.90"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=10000, max_t=300, print_every=100):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        agent.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "    return scores\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.24824894e+03 -2.96448577e+03 -1.21897315e+00 -3.18149626e+03\n",
      " -7.34271397e+03 -7.23287092e+03 -8.17018833e+03 -4.39173108e+03\n",
      " -2.89358518e+03 -7.52767030e+03]\n"
     ]
    }
   ],
   "source": [
    "print(scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Watch a Smart Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2396273311609138 False\n",
      "0.23962733117704452 False\n",
      "0.23962733119123836 False\n",
      "0.2396273517189647 False\n",
      "0.2396273517393759 False\n",
      "0.23962735173856986 False\n",
      "0.2396273517538285 False\n",
      "0.2396273722640375 False\n",
      "0.2396273722864819 False\n",
      "0.23962737228470699 False\n",
      "0.23962737229924103 False\n",
      "0.23962739281639162 False\n",
      "0.23962739282470796 False\n",
      "0.23962739283108714 False\n",
      "0.23962739286818868 False\n",
      "0.23962739285763127 False\n",
      "0.23962741338487334 False\n",
      "0.23962741340003377 False\n",
      "0.23962741341272648 False\n",
      "0.23962741342007352 False\n",
      "0.23962743394736166 False\n",
      "0.23962743395383673 False\n",
      "0.2396274339761825 False\n",
      "0.23962743398256045 False\n",
      "0.23962743398806652 False\n",
      "0.2396274545168075 False\n",
      "0.23962745454512535 False\n",
      "0.23962745456256349 False\n",
      "0.23962745455103585 False\n",
      "0.2396274750957445 False\n",
      "0.23962747510318724 False\n",
      "0.23962747512553187 False\n",
      "0.23962747513094002 False\n",
      "0.23962747515435007 False\n",
      "0.23962749566615474 False\n",
      "0.23962749568849884 False\n",
      "0.2396274956940034 False\n",
      "0.2396274957173161 False\n",
      "0.23962751622897793 False\n",
      "0.23962751625107684 False\n",
      "0.23962751625060874 False\n",
      "0.23962751627979623 False\n",
      "0.23962751627995524 False\n",
      "0.23962753681597873 False\n",
      "0.23962753683638396 False\n",
      "0.2396275368446972 False\n",
      "0.23962753685898228 False\n",
      "0.23962755737015975 False\n",
      "0.23962755737653482 False\n",
      "0.23962755741494152 False\n",
      "0.23962755740534902 False\n",
      "0.23962757793215217 False\n",
      "0.23962757795652892 False\n",
      "0.23962757796193454 False\n",
      "0.23962757798524525 False\n",
      "0.23962757798540305 False\n",
      "0.23962759851997298 False\n",
      "0.23962759854134535 False\n",
      "0.23962759853369 False\n",
      "0.23962759855700025 False\n",
      "0.23962759856250185 False\n",
      "0.23962761909027375 False\n",
      "0.23962761909577507 False\n",
      "0.23962761911811573 False\n",
      "0.23962761915705072 False\n",
      "0.2396276396522609 False\n",
      "0.23962763967566716 False\n",
      "0.23962763968204007 False\n",
      "0.23962763970534923 False\n",
      "0.23962763972841333 False\n",
      "0.23962766023959065 False\n",
      "0.23962766026096113 False\n",
      "0.23962766026733345 False\n",
      "0.23962766028258442 False\n",
      "0.23962768080302818 False\n",
      "0.239627680808431 False\n",
      "0.23962768083270847 False\n",
      "0.23962768083917715 False\n",
      "0.23962768086054673 False\n",
      "0.23962770138831838 False\n",
      "0.23962770139478676 False\n",
      "0.2396277014171252 False\n",
      "0.23962770142446563 False\n",
      "0.23962772194345555 False\n",
      "0.23962772194992343 False\n",
      "0.23962772197226134 False\n",
      "0.23962772197925936 False\n",
      "0.23962772199378454 False\n",
      "0.23962774252883823 False\n",
      "0.2396277425289928 False\n",
      "0.23962774255817318 False\n",
      "0.23962774256648206 False\n",
      "0.23962776307814415 False\n",
      "0.23962776309960862 False\n",
      "0.23962776310791725 False\n",
      "0.23962776312894238 False\n",
      "0.23962776313637837 False\n",
      "0.2396277836723044 False\n",
      "0.23962778368585885 False\n",
      "0.23962778370100996 False\n",
      "0.2396277837152884 False\n",
      "0.23962780422549618 False\n",
      "0.23962780424161645 False\n",
      "0.2396278042542008 False\n",
      "0.2396278042625085 False\n",
      "0.23962782478843786 False\n",
      "0.23962782481271225 False\n",
      "0.23962782483407785 False\n",
      "0.23962782484238518 False\n",
      "0.23962782485666254 False\n",
      "0.23962784537613685 False\n",
      "0.23962784539031698 False\n",
      "0.23962784540580892 False\n",
      "0.23962784541130394 False\n",
      "0.239627865955042 False\n",
      "0.2396278659633487 False\n",
      "0.2396278659687464 False\n",
      "0.23962786599117727 False\n",
      "0.23962786599720198 False\n",
      "0.23962788650250647 False\n",
      "0.23962788653949463 False\n",
      "0.23962788653804926 False\n",
      "0.23962788656047954 False\n",
      "0.23962788656747327 False\n",
      "0.2396279070868051 False\n",
      "0.2396279071097653 False\n",
      "0.23962790713306784 False\n",
      "0.23962790713759136 False\n",
      "0.2396279276521628 False\n",
      "0.23962792766046823 False\n",
      "0.23962792766877355 False\n",
      "0.2396279276776091 False\n",
      "0.23962792770100805 False\n",
      "0.2396279277093131 False\n",
      "0.2396279482233028 False\n",
      "0.23962794822976513 False\n",
      "0.23962794824685182 False\n",
      "0.23962794825602945 False\n",
      "0.23962794827214612 False\n",
      "0.23962796878526316 False\n",
      "0.23962796877663137 False\n",
      "0.23962796880090234 False\n",
      "0.23962796880983406 False\n",
      "0.2396279688031418 False\n",
      "0.2396279687935398 False\n",
      "0.23962798930762677 False\n",
      "0.23962798929996446 False\n",
      "0.23962798929230206 False\n",
      "0.2396279892836697 False\n",
      "0.23962798929197365 False\n",
      "0.23962798930115045 False\n",
      "0.2396280097890344 False\n",
      "0.2396280097901535 False\n",
      "0.23962800978152082 False\n",
      "0.23962800978982438 False\n",
      "0.2396280097680381 False\n",
      "0.23962800979046495 False\n",
      "0.2396280302884888 False\n",
      "0.23962803027801272 False\n",
      "0.239628030288159 False\n",
      "0.2396280302804958 False\n",
      "0.23962803027283255 False\n",
      "0.23962803026613932 False\n",
      "0.2396280302584759 False\n",
      "0.23962805074640525 False\n",
      "0.2396280507706744 False\n",
      "0.23962805074704452 False\n",
      "0.23962805073841084 False\n",
      "0.2396280507457434 False\n",
      "0.23962807125789065 False\n",
      "0.2396280712632828 False\n",
      "0.2396280712703692 False\n",
      "0.2396280712767312 False\n",
      "0.23962807129124766 False\n",
      "0.23962808154137744 False\n",
      "0.23962808157967155 False\n",
      "0.23962808157787852 False\n",
      "0.23962808159214863 False\n",
      "0.23962810210235533 False\n",
      "0.2396281021077463 False\n",
      "0.23962810213104377 False\n",
      "0.2396281021355613 False\n",
      "0.23962812264736544 False\n",
      "0.23962812266188074 False\n",
      "0.23962812266630085 False\n",
      "0.23962812268144315 False\n",
      "0.23962812269464473 False\n",
      "0.2396281431898555 False\n",
      "0.23962814322106055 False\n",
      "0.2396281432274206 False\n",
      "0.23962814323281018 False\n",
      "0.23962816374350185 False\n",
      "0.2396281637518022 False\n",
      "0.23962816377378474 False\n",
      "0.23962816378742538 False\n",
      "0.2396281637915009 False\n",
      "0.23962818429486624 False\n",
      "0.2396281843162209 False\n",
      "0.23962818432320715 False\n",
      "0.23962818432078414 False\n"
     ]
    }
   ],
   "source": [
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))\n",
    "\n",
    "state = env.reset()\n",
    "for t in range(200):\n",
    "    action = agent.act(state, add_noise=False)\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    print(reward, done)\n",
    "    if done:\n",
    "        break \n",
    "img = env.render()\n",
    "img.show()\n",
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Explore\n",
    "\n",
    "In this exercise, we have provided a sample DDPG agent and demonstrated how to use it to solve an OpenAI Gym environment.  To continue your learning, you are encouraged to complete any (or all!) of the following tasks:\n",
    "- Amend the various hyperparameters and network architecture to see if you can get your agent to solve the environment faster than this benchmark implementation.  Once you build intuition for the hyperparameters that work well with this environment, try solving a different OpenAI Gym task!\n",
    "- Write your own DDPG implementation.  Use this code as reference only when needed -- try as much as you can to write your own algorithm from scratch.\n",
    "- You may also like to implement prioritized experience replay, to see if it speeds learning.  \n",
    "- The current implementation adds Ornsetein-Uhlenbeck noise to the action space.  However, it has [been shown](https://blog.openai.com/better-exploration-with-parameter-noise/) that adding noise to the parameters of the neural network policy can improve performance.  Make this change to the code, to verify it for yourself!\n",
    "- Write a blog post explaining the intuition behind the DDPG algorithm and demonstrating how to use it to solve an RL environment of your choosing.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
